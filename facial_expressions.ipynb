{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ElHOmmrBst6"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RriIRuKGBst9"
   },
   "outputs": [],
   "source": [
    "# importing required libraries and packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWviSwlkBst-"
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMdW__2vBst_"
   },
   "outputs": [],
   "source": [
    "# Utility function to plot images\n",
    "# Created by Kaushal Raj Mishra - https://github.com/kaushu42\n",
    "def plot_grid(images, n_rows=4, n_cols=4, figsize=(5, 5), randomize=True, cmap=\"gray\"):\n",
    "    if randomize:\n",
    "        images = images.copy()\n",
    "        np.random.shuffle(images)\n",
    "    fig = plot.figure(figsize=figsize)\n",
    "    grid = ImageGrid(\n",
    "            fig, 111,\n",
    "            # creates 2x2 grid of axes\n",
    "            nrows_ncols=(n_rows, n_cols), \n",
    "            # pad between axes in inch.\n",
    "            axes_pad=0.1,  \n",
    "        )\n",
    "    for ax, im in zip(grid, iter(images)):\n",
    "        ax.imshow(im, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHQa7otKBsuA"
   },
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suCriaFYBsuB"
   },
   "outputs": [],
   "source": [
    "# Paths to locate static files\n",
    "DATASET_PATH = \"FER2013.csv\"\n",
    "HAARCASCADE_PATH = \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gzhPMghBsuB"
   },
   "source": [
    "### Reading the data from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYIWAMx1BsuC"
   },
   "outputs": [],
   "source": [
    "# creating a datafram fetching the data from the dataset\n",
    "dataframe = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQRBxrocBsuD",
    "outputId": "fc184b5f-f5e1-4e4f-dad0-b18c8db62158"
   },
   "outputs": [],
   "source": [
    "# Getting the summary of dataset\n",
    "print(dataframe.Usage.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "HzGLhy4G8gwC",
    "outputId": "6713314d-d54b-4b41-efe8-c00b94d8216f"
   },
   "outputs": [],
   "source": [
    "# Getting the total ditribution of images based on usage and plotting in the graph\r\n",
    "dataframe.Usage.value_counts().plot.bar(color=\"green\")\r\n",
    "plot.title(\"Dataset\")\r\n",
    "plot.xlabel(\"Dataset Usage\")\r\n",
    "plot.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "ADxNlwV2-fXB",
    "outputId": "4c8e73cf-cfb4-4d5d-aeaf-6ececef7ddfd"
   },
   "outputs": [],
   "source": [
    "# Getting the distribution of emotion class and plotting in the graph\r\n",
    "dataframe.emotion.value_counts().plot.bar(color=\"orange\")\r\n",
    "plot.title(\"Emotions\")\r\n",
    "plot.xlabel(\"Emotion Class\")\r\n",
    "plot.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54bkqodaBsuE"
   },
   "source": [
    "### Conversion, Allocation and Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqo9NKCDBsuE"
   },
   "outputs": [],
   "source": [
    "# Defining a funciton to convert the pixel strings into integers\n",
    "def convert_pixels(pixels_string):\n",
    "#     returning a converted int pixels value \n",
    "    return np.fromstring(pixels_string, dtype=int, sep=\" \").reshape(48, 48, 1)\n",
    "\n",
    "# assigning converted pixel values into dataframe\n",
    "# appy function is used to converted each sting pixels into int\n",
    "dataframe[\"px_array\"] = dataframe.pixels.apply(convert_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyVmjIP2BsuF"
   },
   "outputs": [],
   "source": [
    "# Assiging the training and testing data based on Usage column on the dataset\n",
    "train_data = dataframe.query(\"Usage == 'Training'\")\n",
    "test_data = dataframe.query(\"Usage != 'Training'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnmLIz05BsuF"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data for training set\n",
    "x_train = np.stack(train_data.px_array)/255\n",
    "y_train = train_data.emotion\n",
    "\n",
    "# Normalizing the data for test set\n",
    "x_test = np.stack(test_data.px_array)/255\n",
    "y_test = test_data.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9WjdPk7BsuF"
   },
   "outputs": [],
   "source": [
    "# Plotting the summary of images from dataset using utility functions\n",
    "# plot_grid(x_train, 5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1chgyTq2BsuG"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding train and test data set to get a single emotion with high probability\n",
    "y_train_catg = to_categorical(y_train)\n",
    "y_test_catg = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnE08I7bAfaZ"
   },
   "source": [
    "### Data Augmetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TWji_IXAkmE"
   },
   "outputs": [],
   "source": [
    "# Generating extra images by modifying the properties of data in exsiting dataset\r\n",
    "# This is done to increase the data size for a better trained model\r\n",
    "image_generator = ImageDataGenerator(\r\n",
    "        rotation_range=5,  \r\n",
    "        width_shift_range=0.2,  \r\n",
    "        height_shift_range=0.2,  \r\n",
    "        zoom_range = 0.1,\r\n",
    "        shear_range = 10,  \r\n",
    "        horizontal_flip=True, \r\n",
    "        validation_split=0.2\r\n",
    ")\r\n",
    "\r\n",
    "# Allocating the augmented data to training and testing sets\r\n",
    "train_iterate = image_generator.flow(x_train, y_train_catg, batch_size=128, subset='training')\r\n",
    "val_iterate = image_generator.flow(x_train, y_train_catg, batch_size=128, subset='validation')  \r\n",
    "\r\n",
    "# Iterating on genrator object to generate iamge data\r\n",
    "gen_x, gen_y = next(train_iterate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmGV6D5JBsuH"
   },
   "source": [
    "### Creating CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-UGzl69BsuH",
    "outputId": "0be62dae-c2fd-4445-8d28-ab2a236b794e"
   },
   "outputs": [],
   "source": [
    "# Clearing previous models and sessions\n",
    "clear_session()\n",
    "\n",
    "# Defining model layers\n",
    "input_layer = Input(shape=(48, 48, 1))\n",
    "layers = Conv2D(64, 3, 1, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = MaxPooling2D()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "layers = Conv2D(128, 3, 1, activation=\"relu\", padding=\"same\")(layers)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = MaxPooling2D()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "layers = Conv2D(512, 3, 1, activation=\"relu\", padding=\"same\")(layers)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = MaxPooling2D()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "layers = Conv2D(512, 3, 1, activation=\"relu\", padding=\"same\")(layers)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = MaxPooling2D()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "layers = Flatten()(layers)\n",
    "layers = Dense(256, activation=\"relu\")(layers)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "layers = Dense(512, activation=\"relu\")(layers)\n",
    "layers = BatchNormalization()(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "layers = Dense(7, activation=\"softmax\")(layers)\n",
    "\n",
    "# Defining input, hidden and output layers\n",
    "model = Model(inputs=[input_layer], outputs=[layers])\n",
    "# Showing the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5YYLBuzBsuI"
   },
   "outputs": [],
   "source": [
    "# Defining callbacks for the model while training\n",
    "# param: patience - iterations to wait before stopping when val loss is not improving\n",
    "my_callbacks = [EarlyStopping(patience=10, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xWs6b-5GBsuI",
    "outputId": "ec5c61d0-11a0-41fa-cf5d-7c420abdb518"
   },
   "outputs": [],
   "source": [
    "# Plotting the model architecture\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3R8NeJBBsuJ"
   },
   "source": [
    "### Compiling and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_l4swbzBsuJ"
   },
   "outputs": [],
   "source": [
    "# Compiling the created model\n",
    "# Params : loss = loss function\n",
    "# optimizer : optimizer type to be used\n",
    "# metrics : Metrics to be shown while training the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Calculating class weights for balanced distribution of emotions classes\n",
    "weights = compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "# Enumerating weights in the form of dictionary\n",
    "weights = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTnAq2pDBsuJ",
    "outputId": "a4c6aa96-8609-4100-936a-9fcc02fb889f"
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# Params : epochs - number of epochs\n",
    "# batch_size : batch size of the train data\n",
    "# class_weight : weights for the classes\n",
    "# validation_data: validation data set\n",
    "# callbacks : callbacks to run while training the model\n",
    "train_model = model.fit(train_iterate, epochs=100, batch_size=128, class_weight=weights, validation_data=val_iterate, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dwhKxwIBsuK"
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGda7jdvBsuK"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN4vssIJBsuK"
   },
   "source": [
    "### Training Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f9nWrTbBsuK",
    "outputId": "bcb884bc-e9e9-4d4e-9a59-8c9534c30c7f"
   },
   "outputs": [],
   "source": [
    "# Evaluating the trained model using test data\r\n",
    "model.evaluate(x_test, y_test_catg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhfF98ZuBsuL"
   },
   "outputs": [],
   "source": [
    "# Getting the training and validation loss and accuracy from the model\n",
    "training_loss = train_model.history[\"loss\"]\n",
    "validation_loss = train_model.history[\"val_loss\"]\n",
    "training_acc = train_model.history[\"accuracy\"]\n",
    "validation_acc = train_model.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "5ie6CfU6BsuL",
    "outputId": "32bf545a-beef-42dc-95ae-2f71e84d79c5"
   },
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss in the graph using matplotlib\n",
    "plot.plot(training_loss, label=\"Train loss\")\n",
    "plot.plot(validation_loss, label=\"Validation loss\")\n",
    "plot.ylabel('Loss')\n",
    "plot.xlabel('Epochs')\n",
    "plot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "qLH4gDfe0y_c",
    "outputId": "93617614-c778-43c2-f5b7-be903303b79d"
   },
   "outputs": [],
   "source": [
    "# Plotting the training and validation accuracy in the graph using matplotlib\r\n",
    "plot.plot(training_acc, label=\"Train Accuracy\")\r\n",
    "plot.plot(validation_acc, label=\"Validation Accuracy\", color=\"red\")\r\n",
    "plot.ylabel('Accuracy')\r\n",
    "plot.xlabel('Epochs')\r\n",
    "plot.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YB5537LDBsuL"
   },
   "source": [
    "### Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJMeXFYFE0Ww"
   },
   "outputs": [],
   "source": [
    "# Defining a list to store the emotion strings based on their class index from dataset\r\n",
    "emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m87hbtLaBsuM",
    "outputId": "3f95cc6d-86d2-4c89-a3ac-96793380a788"
   },
   "outputs": [],
   "source": [
    "# Predictions and reports on Training data\n",
    "predictions = model.predict(x_train).argmax(axis=1)\n",
    "print(classification_report(y_train, predictions))\n",
    "print(confusion_matrix(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "8JD2biGuBqdr",
    "outputId": "2c649bc0-5c4c-4119-f97d-2a8aeeb05aa5"
   },
   "outputs": [],
   "source": [
    "# Graphically representing the confusion matrix \r\n",
    "confusion_matrix_plot = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, predictions),display_labels=emotions)\r\n",
    "# changing the size of the graph\r\n",
    "_, ax = plot.subplots(figsize=(10, 10))\r\n",
    "# Setting the title for the graph\r\n",
    "plot.title(\"Train Confusion Matrix\")\r\n",
    "# setting extra attributes for customizations\r\n",
    "confusion_matrix_plot = confusion_matrix_plot.plot(include_values=True,cmap=\"plasma\",xticks_rotation=\"60.0\",ax=ax,values_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dffcpspmBsuM",
    "outputId": "91578b7b-10bd-4307-aa95-0bdccf9bf4b7"
   },
   "outputs": [],
   "source": [
    "# Predictions and reports on Testing data\n",
    "predictions = model.predict(x_test).argmax(axis=1)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "bgxJ3lE_EqMp",
    "outputId": "8968b8ff-930f-4fdc-d088-8b8e0093d45e"
   },
   "outputs": [],
   "source": [
    "# Graphically representing the confusion matrix \r\n",
    "confusion_matrix_plot = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predictions),display_labels=emotions)\r\n",
    "# changing the size of the graph\r\n",
    "_, ax = plot.subplots(figsize=(10, 10))\r\n",
    "# Setting the title for the graph\r\n",
    "plot.title(\"Test Confusion Matrix\")\r\n",
    "# setting extra attributes for customizations\r\n",
    "confusion_matrix_plot = confusion_matrix_plot.plot(include_values=True,cmap=\"plasma\",xticks_rotation=\"60.0\",ax=ax,values_format='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bn-LCwXWGJHk"
   },
   "source": [
    "### Testing Model for Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "-T_uckkHGGtj",
    "outputId": "1abd76ad-0361-4f11-ecdf-33d41a9a9cc1"
   },
   "outputs": [],
   "source": [
    "# Index of the image in dataset to test\r\n",
    "test_index = 1800\r\n",
    "# Getting the image from the dataset from given index\r\n",
    "test_image = x_test[test_index].reshape(48, 48)\r\n",
    "# Showing the selected image\r\n",
    "plot.imshow(test_image,cmap=\"gray\")\r\n",
    "# Showing the predicted class and actual class of emotions for the selected image\r\n",
    "print(\"Actual: \",emotions[np.stack(y_test)[test_index]])\r\n",
    "print(\"Predicted: \",emotions[predictions[test_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPp-IgqiBsuN"
   },
   "source": [
    "### --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q50N03YCBsuN"
   },
   "source": [
    "# Live Testing the Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqyA7WTvBsuO"
   },
   "source": [
    "### --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rir_TBa1BsuO"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oU_3_bqBBsuO"
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChRZrkfHBsuP"
   },
   "source": [
    "### Setting up Faces Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41gDIRWjBsuP"
   },
   "outputs": [],
   "source": [
    "# Defining a list to store the emotion strings based on their class index from dataset\n",
    "emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "# Using haar cascade classifiers to extract the face from the images from camera\n",
    "f_classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7oZH5jqBsuQ"
   },
   "source": [
    "### Loading the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Asle8E4RBsuQ"
   },
   "outputs": [],
   "source": [
    "# Loading the saved trained model for expression detection\n",
    "model = load_model(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p68VdjVTBsuR"
   },
   "source": [
    "### Starting Camera and Detecting Facial Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vL5Z2YgdBsuR"
   },
   "source": [
    "#### Press 'x' to Exit Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYlrQ2FeBsuR"
   },
   "outputs": [],
   "source": [
    "# Starting the default device camera using cv2\n",
    "camera = cv.VideoCapture(0)\n",
    "\n",
    "# Starting while loop to continuously read objects from camera\n",
    "while True:\n",
    "    #  Reading image from camera\n",
    "    _, camera_frame = camera.read()\n",
    "    # Getting face from the image and coverting it to grayscale image\n",
    "    gray = cv.cvtColor(camera_frame,cv.COLOR_BGR2GRAY)\n",
    "    # Detecting faces seen on the camera image\n",
    "    faces = f_classifier.detectMultiScale(gray,1.3,5)\n",
    "    # Adding text to the window to display the number of faces detected\n",
    "    cv.putText(camera_frame, f'{len(faces)} Faces Found', (20, 25), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv.LINE_AA) \n",
    "    cv.putText(camera_frame, \"Press 'x' To Exit\", (500, 25), cv.FONT_HERSHEY_SIMPLEX,  0.5, (0, 255, 0), 2, cv.LINE_AA) \n",
    "    for (x,y,w,h) in faces:\n",
    "        # Drawing bounding box around face and extreacting the image\n",
    "        cv.rectangle(camera_frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        # Extracting the face from the image\n",
    "        gray_roi = gray[y:y+h,x:x+w]\n",
    "        gray_roi = cv.resize(gray_roi,(48,48),interpolation=cv.INTER_AREA)\n",
    "        # rect,face,image = face_detector(camera_frame)\n",
    "        if np.sum([gray_roi])!=0:\n",
    "            region_of_int = gray_roi.astype('float')/255.0\n",
    "            region_of_int = img_to_array(region_of_int)\n",
    "            region_of_int = np.expand_dims(region_of_int,axis=0)\n",
    "            # make a prediction on the region_of_int, then lookup the class\n",
    "            preds = model.predict(region_of_int)[0]\n",
    "            # Defining labels of emotions\n",
    "            emotion_label=emotions[preds.argmax()]\n",
    "            label_position = (x,y)\n",
    "            # Showing emotion text\n",
    "            cv.putText(camera_frame,emotion_label,label_position,cv.FONT_HERSHEY_SIMPLEX,1,(0,255,255),3)\n",
    "    # Displaying the camera output in a window\n",
    "    cv.imshow('Facial Expressions Detection',camera_frame)\n",
    "    # Defining exit key for the camera window ('x' in this case) and breaking the loop\n",
    "    if cv.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "        \n",
    "# Releasing all the camera resources and windows used by cv2\n",
    "camera.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4LoiPi4BsuS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
